{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88ebeab1-44ad-4435-a06c-088596950937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# 1. إعدادات Event Hub\n",
    "event_hub_namespace = \"rg-hospital-eh\"\n",
    "event_hub_name = \"rg-hospital-eh\"\n",
    "connection_string = \"Endpoint=sb://rg-hospital-eh.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=NsWvR2hMHKIpCfNUffBHwPYMUnwxplUW++AEhJuO/0M=\"\n",
    "\n",
    "kafka_options = {\n",
    "    'kafka.bootstrap.servers': f\"{event_hub_namespace}.servicebus.windows.net:9093\",\n",
    "    'subscribe': event_hub_name,\n",
    "    'kafka.security.protocol': 'SASL_SSL',\n",
    "    'kafka.sasl.mechanism': 'PLAIN',\n",
    "    'kafka.sasl.jaas.config': f'kafkashaded.org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"{connection_string}\";',\n",
    "    'startingOffsets': 'earliest', # تأكد أنها earliest\n",
    "    'failOnDataLoss': 'false'\n",
    "}\n",
    "\n",
    "# 2. قراءة الستريم\n",
    "raw_df = (spark.readStream\n",
    "          .format(\"kafka\")\n",
    "          .options(**kafka_options)\n",
    "          .load())\n",
    "\n",
    "json_df = raw_df.selectExpr(\"CAST(value AS STRING) as raw_json\")\n",
    "\n",
    "# 3. إعدادات التخزين (الحساب الجديد 17)\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.hospitalstorge17.dfs.core.windows.net\",\n",
    "    \"WvLwnc4iFRFgHew6zE9Y55DklpACeOYhA5a3Uz5oCbe16zK0seQxJRs96m5KV4lpDHY56LkqZ3NH+AStfb+C3A==\"\n",
    ")\n",
    "\n",
    "# 4. تحديد المسارات\n",
    "# سنضع البيانات في bronze_real\n",
    "bronze_path = \"abfss://bronze@hospitalstorge17.dfs.core.windows.net/bronze_real\"\n",
    "# سنضع الشيك بوينت في مجلد _checkpoints داخل نفس المكان لضمان الوصول\n",
    "checkpoint_path = \"abfss://bronze@hospitalstorge17.dfs.core.windows.net/_checkpoints/patient_flow_v3\"\n",
    "\n",
    "# 5. تنظيف الشيك بوينت القديم (اختياري لكن مفيد لضمان البداية النظيفة)\n",
    "# dbutils.fs.rm(checkpoint_path, True) \n",
    "\n",
    "# 6. الكتابة\n",
    "query = (json_df\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path) # مسار جديد كلياً\n",
    "    .start(bronze_path)\n",
    ")\n",
    "\n",
    "# عرض البيانات للتأكد (لا تستخدمها في الإنتاج، فقط للاختبار)\n",
    "# display(json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "787dd71a-eaa2-4700-b160-4a0948706918",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.0-bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
